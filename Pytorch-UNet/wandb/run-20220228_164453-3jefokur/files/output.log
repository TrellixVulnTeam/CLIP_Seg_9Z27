INFO: Starting training:
        Epochs:          50
        Batch size:      32
        Learning rate:   2e-07
        Training size:   1464
        Validation size: 1449
        Checkpoints:     True
        Device:          cuda
        Images scaling:  0.5
        Mixed Precision: True
Epoch 1/50:   0%|                                                          | 0/1464 [00:00<?, ?img/s]/home/dvir/anaconda3/envs/CLIP_Seg/lib/python3.8/site-packages/torch/nn/functional.py:3609: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  warnings.warn(
/home/dvir/anaconda3/envs/CLIP_Seg/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /tmp/pip-req-build-pyrtjkcs/c10/core/TensorImpl.h:1156.)
  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
Epoch 1/50:   0%|                                                          | 0/1464 [00:05<?, ?img/s]
Traceback (most recent call last):
  File "train.py", line 325, in <module>
    train_net(net=torch.nn.DataParallel(net, device_ids=list(map(int, args.device_ids.split(",")))),
  File "train.py", line 227, in train_net
    masks_pred = net(images)
  File "/home/dvir/anaconda3/envs/CLIP_Seg/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/dvir/anaconda3/envs/CLIP_Seg/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py", line 168, in forward
    outputs = self.parallel_apply(replicas, inputs, kwargs)
  File "/home/dvir/anaconda3/envs/CLIP_Seg/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py", line 178, in parallel_apply
    return parallel_apply(replicas, inputs, kwargs, self.device_ids[:len(replicas)])
  File "/home/dvir/anaconda3/envs/CLIP_Seg/lib/python3.8/site-packages/torch/nn/parallel/parallel_apply.py", line 86, in parallel_apply
    output.reraise()
  File "/home/dvir/anaconda3/envs/CLIP_Seg/lib/python3.8/site-packages/torch/_utils.py", line 425, in reraise
    raise self.exc_type(msg)
RuntimeError: Caught RuntimeError in replica 1 on device 1.
Original Traceback (most recent call last):
  File "/home/dvir/anaconda3/envs/CLIP_Seg/lib/python3.8/site-packages/torch/nn/parallel/parallel_apply.py", line 61, in _worker
    output = module(*input, **kwargs)
  File "/home/dvir/anaconda3/envs/CLIP_Seg/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/dvir/CLIP_Seg/Pytorch-UNet/unet/unet_model.py", line 26, in forward
    x1 = self.inc(x)
  File "/home/dvir/anaconda3/envs/CLIP_Seg/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/dvir/CLIP_Seg/Pytorch-UNet/unet/unet_parts.py", line 25, in forward
    return self.double_conv(x)
  File "/home/dvir/anaconda3/envs/CLIP_Seg/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/dvir/anaconda3/envs/CLIP_Seg/lib/python3.8/site-packages/torch/nn/modules/container.py", line 139, in forward
    input = module(input)
  File "/home/dvir/anaconda3/envs/CLIP_Seg/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/dvir/anaconda3/envs/CLIP_Seg/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py", line 167, in forward
    return F.batch_norm(
  File "/home/dvir/anaconda3/envs/CLIP_Seg/lib/python3.8/site-packages/torch/nn/functional.py", line 2281, in batch_norm
    return torch.batch_norm(
RuntimeError: CUDA out of memory. Tried to allocate 98.00 MiB (GPU 1; 10.76 GiB total capacity; 235.94 MiB already allocated; 15.19 MiB free; 250.00 MiB reserved in total by PyTorch)