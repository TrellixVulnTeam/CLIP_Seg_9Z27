INFO: Starting training:
        Epochs:          5
        Batch size:      32
        Learning rate:   1e-07
        Training size:   1464
        Validation size: 1449
        Checkpoints:     True
        Device:          cuda
        Images scaling:  0.5
        Mixed Precision: True
Epoch 1/5:   0%|                                                           | 0/1464 [00:00<?, ?img/s]/home/dvir/anaconda3/envs/CLIP_Seg/lib/python3.8/site-packages/torch/nn/functional.py:3609: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  warnings.warn(
/home/dvir/anaconda3/envs/CLIP_Seg/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /tmp/pip-req-build-pyrtjkcs/c10/core/TensorImpl.h:1156.)
  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
Epoch 1/5:   0%|                                                           | 0/1464 [00:07<?, ?img/s]
Traceback (most recent call last):
  File "train.py", line 284, in <module>
    train_net(net=torch.nn.DataParallel(net),
  File "train.py", line 191, in train_net
    masks_pred = net(images)
  File "/home/dvir/anaconda3/envs/CLIP_Seg/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/dvir/anaconda3/envs/CLIP_Seg/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py", line 168, in forward
    outputs = self.parallel_apply(replicas, inputs, kwargs)
  File "/home/dvir/anaconda3/envs/CLIP_Seg/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py", line 178, in parallel_apply
    return parallel_apply(replicas, inputs, kwargs, self.device_ids[:len(replicas)])
  File "/home/dvir/anaconda3/envs/CLIP_Seg/lib/python3.8/site-packages/torch/nn/parallel/parallel_apply.py", line 86, in parallel_apply
    output.reraise()
  File "/home/dvir/anaconda3/envs/CLIP_Seg/lib/python3.8/site-packages/torch/_utils.py", line 425, in reraise
    raise self.exc_type(msg)
RuntimeError: Caught RuntimeError in replica 2 on device 2.
Original Traceback (most recent call last):
  File "/home/dvir/anaconda3/envs/CLIP_Seg/lib/python3.8/site-packages/torch/nn/parallel/parallel_apply.py", line 61, in _worker
    output = module(*input, **kwargs)
  File "/home/dvir/anaconda3/envs/CLIP_Seg/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/dvir/CLIP_Seg/Pytorch-UNet/unet/unet_model.py", line 34, in forward
    x = self.up4(x, x1)
  File "/home/dvir/anaconda3/envs/CLIP_Seg/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/dvir/CLIP_Seg/Pytorch-UNet/unet/unet_parts.py", line 62, in forward
    x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,
  File "/home/dvir/anaconda3/envs/CLIP_Seg/lib/python3.8/site-packages/torch/nn/functional.py", line 4153, in _pad
    return _VF.constant_pad_nd(input, pad, value)
RuntimeError: CUDA out of memory. Tried to allocate 62.00 MiB (GPU 2; 1.95 GiB total capacity; 1.18 GiB already allocated; 53.38 MiB free; 1.22 GiB reserved in total by PyTorch)